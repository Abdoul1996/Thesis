{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "50356e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import numpy as np \n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cc0e5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = \"/Users/abdoulabdillahi/Desktop/Thesis/Bio_project/200_samples_with_encoded.csv\"\n",
    "NUCLEOTIDE_TO_INT = {'A':0, 'C':1, 'G':2, 'T':3, '-':4, 'N':5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3362fee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "## configuration to detect cuda or cpu\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print (device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977e8a9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb1228c8",
   "metadata": {},
   "source": [
    "# Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a52de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneDataset(Dataset):\n",
    "    def __init__(self, csv_file, label_col='Ciprofloxacin_NS', gene_prefix='gene_', quantile=80,  transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (str): Path to the CSV.\n",
    "            label_col (str): Column with binary labels.\n",
    "            gene_prefix (str): Prefix of gene columns (default: 'gene_').\n",
    "            quantile (int): Quantile (%) to determine seq_len (e.g., 95 means use 95th percentile of lengths).\n",
    "        \"\"\"\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        self.label_col = label_col\n",
    "        self.gene_cols = [c for c in self.df.columns if c.startswith(gene_prefix)]\n",
    "        \n",
    "        # Compute seq_len using quantile of all sequence lengths\n",
    "        all_lengths = []\n",
    "        for row in self.df[self.gene_cols].itertuples(index=False):\n",
    "            for cell in row:\n",
    "                if pd.isna(cell): continue\n",
    "                if isinstance(cell, str) and cell.startswith('['):\n",
    "                    tokens = cell.strip(\"[]\").replace(\"'\", \"\").split()\n",
    "                    tokens = [t for t in tokens if t.lower() != 'nan']\n",
    "                else:\n",
    "                    tokens = list(str(cell))\n",
    "                all_lengths.append(len(tokens))\n",
    "\n",
    "        self.seq_len = int(np.percentile(all_lengths, quantile))\n",
    "        print(f\"[INFO] Using seq_len={self.seq_len} based on {quantile}th percentile of sequence lengths.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def encode_sequence(self, tokens):\n",
    "        ids = [NUCLEOTIDE_TO_INT.get(t.upper(), NUCLEOTIDE_TO_INT['N']) for t in tokens]\n",
    "        # Pad or truncate\n",
    "        if len(ids) < self.seq_len:\n",
    "            ids += [NUCLEOTIDE_TO_INT['N']] * (self.seq_len - len(ids))\n",
    "        else:\n",
    "            ids = ids[:self.seq_len]\n",
    "        return ids\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        label = int(row[self.label_col]) # extract label col\n",
    "        features = []\n",
    "\n",
    "        for col in self.gene_cols:\n",
    "            cell = row[col]\n",
    "            if pd.isna(cell):\n",
    "                features.extend([NUCLEOTIDE_TO_INT['N']] * self.seq_len)\n",
    "                continue\n",
    "\n",
    "            if isinstance(cell, str) and cell.startswith('['):\n",
    "                tokens = cell.strip(\"[]\").replace(\"'\", \"\").split()\n",
    "                tokens = [t for t in tokens if t.lower() != 'nan']\n",
    "            else:\n",
    "                tokens = list(str(cell))\n",
    "\n",
    "            encoded = self.encode_sequence(tokens)\n",
    "            features.extend(encoded)\n",
    "\n",
    "        return torch.tensor(features, dtype=torch.float32), torch.tensor(label, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce436d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using seq_len=174 based on 80th percentile of sequence lengths.\n",
      "torch.Size([32, 2719446])\n",
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "dataset = GeneDataset(path_to_data)  # Automatically computes best seq_len\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "for x, y in dataloader:\n",
    "    print(x.shape)  # (batch_size, num_genes Ã— seq_len)\n",
    "    print(y.shape)  # (batch_size,)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "687e4df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method GeneDataset.encode_sequence of <__main__.GeneDataset object at 0x31aaf63c0>>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.encode_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89721ac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 3., 2.,  ..., 0., 3., 0.],\n",
       "        [0., 3., 2.,  ..., 5., 5., 5.],\n",
       "        [0., 3., 2.,  ..., 5., 5., 5.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92c9dd5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918065c3",
   "metadata": {},
   "source": [
    "# Logistic Regression in Pytorch \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55182ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.Linear = nn.Linear(input_dim, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.Linear(x).squeeze(1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "719b458b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegressionModel(input_dim=len(dataset[0][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ce60010b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of LogisticRegressionModel(\n",
       "  (Linear): Linear(in_features=2719446, out_features=1, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69c302f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary Cross Entropy Loss\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Optimizer (e.g., Adam or SGD)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d819798",
   "metadata": {},
   "source": [
    "# Training Loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8652892f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 184.4475\n",
      "Epoch 2/10, Loss: 253.8462\n",
      "Epoch 3/10, Loss: 256.0096\n",
      "Epoch 4/10, Loss: 252.4038\n",
      "Epoch 5/10, Loss: 255.2885\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m model.train()\n\u001b[32m      6\u001b[39m running_loss = \u001b[32m0.0\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m X_batch, y_batch \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[32m      9\u001b[39m     \u001b[38;5;66;03m# Ensure target shape matches predictions\u001b[39;00m\n\u001b[32m     10\u001b[39m     y_batch = y_batch.float().view(-\u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# [B, 1]\u001b[39;00m\n\u001b[32m     12\u001b[39m     \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ecoli/lib/python3.13/site-packages/torch/utils/data/dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28mself\u001b[39m._next_data()\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ecoli/lib/python3.13/site-packages/torch/utils/data/dataloader.py:789\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    787\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    788\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m789\u001b[39m     data = \u001b[38;5;28mself\u001b[39m._dataset_fetcher.fetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    790\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    791\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ecoli/lib/python3.13/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28mself\u001b[39m.dataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 58\u001b[39m, in \u001b[36mGeneDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m     55\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     56\u001b[39m         tokens = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mstr\u001b[39m(cell))\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     encoded = \u001b[38;5;28mself\u001b[39m.encode_sequence(tokens)\n\u001b[32m     59\u001b[39m     features.extend(encoded)\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m torch.tensor(features, dtype=torch.float32), torch.tensor(label, dtype=torch.long)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 33\u001b[39m, in \u001b[36mGeneDataset.encode_sequence\u001b[39m\u001b[34m(self, tokens)\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mencode_sequence\u001b[39m(\u001b[38;5;28mself\u001b[39m, tokens):\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m     ids = [NUCLEOTIDE_TO_INT.get(t.upper(), NUCLEOTIDE_TO_INT[\u001b[33m'\u001b[39m\u001b[33mN\u001b[39m\u001b[33m'\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tokens]\n\u001b[32m     34\u001b[39m     \u001b[38;5;66;03m# Pad or truncate\u001b[39;00m\n\u001b[32m     35\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ids) < \u001b[38;5;28mself\u001b[39m.seq_len:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Train for a few epochs\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for X_batch, y_batch in dataloader:\n",
    "        # Ensure target shape matches predictions\n",
    "        y_batch = y_batch.float().view(-1)  # [B, 1]\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(X_batch)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, y_batch)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce67a54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecoli",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
